{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNsAjjrMlsYBxXoqFLFUI86",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyaagrwl/Major-Project/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjfeO-aeWIhe"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oxPQ_xlWOh4"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score\n",
        "wordnet_lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsKGpHOCaYzS"
      },
      "source": [
        "df = pd.read_csv('/content/Tweets.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWesgjXiWTSR"
      },
      "source": [
        "def normalizer(tweet):\n",
        "  only_letters = re.sub(\"[^a-zA-Z]\",\"\",tweet)\n",
        "  only_letters = only_letters.lower()\n",
        "  only_letters = only_letters.split()\n",
        "  filtered_result = [word for word in only_letters if word not in stopwords.words('english')]\n",
        "  lemmas = [wordnet_lemmatizer.lemmatize(t) for t in filtered_result]\n",
        "  lemmas = ' '.join(lemmas)\n",
        "  return lemmas\n",
        "print(normalizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu2rU1tZWWVd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "580750e5-183a-49b1-f58b-cc55f0f919fe"
      },
      "source": [
        "df = shuffle(df)\n",
        "y = df['sentiment']\n",
        "x=df.text.apply(normalizer)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bda6c153d890>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'shuffle' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu0UcDh5WZvG"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "x_vectorized = vectorizer.fit_transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQeNMlWDWcdv"
      },
      "source": [
        "df = df.reindex(labels=df.columns,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZLwJfq8WfcI"
      },
      "source": [
        "train_x,val_x,train_y,val_y=train_test_split(x_vectorized,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTXYrc6DWkAt"
      },
      "source": [
        "regressor = LogisticRegression(multi_class='multinomial',solver='newton-cg')\n",
        "model = regressor.fit(train_x,train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TFu6RNzWk7M"
      },
      "source": [
        "params = {'C':[0.001,0.01,0.1,1,10,100,1000]}\n",
        "gs_clf = GridSearchCV(model,params,n_jobs=1,cv=5)\n",
        "gs_clf = gs_clf.fit(train_x,train_y)\n",
        "model = gs_clf.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFi4TPshWnI1"
      },
      "source": [
        "y_pred = model.predict(val_x)\n",
        "_f1 = f1_score(val_y,y_pred,average='micro')\n",
        "_confusion= confusion_matrix(val_y,y_pred)\n",
        "__precision = precision_score(val_y,y_pred,average='micro')\n",
        "_recall = recall_score(val_y,y_pred,average='micro')\n",
        "_statistics = {\n",
        "                'f1_score':_f1,\n",
        "                'confusion_matrix':_confusion,\n",
        "                'precision_score':__precision,\n",
        "                'recall':_recall\n",
        "              }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz_DMq7mWqYh"
      },
      "source": [
        "print(_statistics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkuJHEwZWtMt"
      },
      "source": [
        "test_feature = vectorizer.transform(['Positive'])\n",
        "model.predict(test_feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DSJ4AchWwNI"
      },
      "source": [
        "test_feature = vectorizer.transform(['Negative'])\n",
        "model.predict(test_feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOth3Y2jWy9l"
      },
      "source": [
        "test_feature = vectorizer.transform(['Neutral'])\n",
        "model.predict(test_feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbHplSclW1Hy"
      },
      "source": [
        "import joblib\n",
        "joblib.dump(model,'model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROtGOzzIW3m6"
      },
      "source": [
        "!pip install streamlit --quiet\n",
        "!pip install pyngrok==4.1.1 --quiet\n",
        "from pyngrok import ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfBDNo-kW6Nd"
      },
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import sklearn\n",
        "import joblib\n",
        "model = joblib.load('model')\n",
        "st.title('Sentiment Analyser')\n",
        "ip = st.text_input('Enter your remarks:')\n",
        "ip = ip.reshape(-1,1)\n",
        "op = model.predict([ip])\n",
        "if st.button('Predict'):\n",
        "  st.title(op[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyk2sjuwW9Sf"
      },
      "source": [
        "!nohup streamlit run app.py &\n",
        "url=ngrok.connect(port='8501')\n",
        "url"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}